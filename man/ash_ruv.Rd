% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ruv_ash.R
\name{ash_ruv}
\alias{ash_ruv}
\title{Use control genes to estimate hidden confounders and variance
inflation parameter, then run ASH.}
\usage{
ash_ruv(Y, X, ctl = NULL, k = NULL, cov_of_interest = ncol(X),
  ash_args = list(), include_intercept = TRUE, gls = TRUE,
  likelihood = c("normal", "t"), limmashrink = FALSE, fa_func = pca_naive,
  fa_args = list())
}
\arguments{
\item{Y}{A matrix of numerics. These are the response variables
where each column has its own variance. In a gene expression
study, the rows are the individuals and the columns are the
genes.}

\item{X}{A matrix of numerics. The covariates of interest.}

\item{ctl}{A vector of logicals of length \code{ncol(Y)}. If
position i is \code{TRUE} then position i is considered a
negative control. If \code{ctl = NULL} (the default) then ASH
will be run on the OLS estimates and corresponding standard
errors.}

\item{k}{A non-negative integer.The number of unobserved
confounders. If not specified and the R package sva is
installed, then this function will estimate the number of
hidden confounders using the methods of Buja and Eyuboglu
(1992).}

\item{cov_of_interest}{A positive integer. The column number of the
covariate in X whose coefficients you want to apply ASH to.}

\item{ash_args}{A list of arguments to pass to ash. See
\code{\link{ash.workhorse}} for details.}

\item{include_intercept}{A logical. If \code{TRUE}, then it will
check \code{X} to see if it has an intercept term. If not, then
it will add an intercept term. If \code{FALSE}, then \code{X}
will be unchanged.}

\item{gls}{A logical. Should we use generalized least squares
(\code{TRUE}) or ordinary least squares (\code{FALSE}) for
estimating the confounders? The OLS version is equivalent to
using RUV4 to estimate the confounders.}

\item{likelihood}{Either \code{"normal"} or \code{"t"}. If
\code{likelihood = "t"}, then the user may provide the degrees
of freedom by including a \code{df} element in
\code{ash_args}. If \code{ash_args$df} is \code{NULL} then the
degrees of freedom will be the sample size minus the number of
covariates minus \code{k}.}

\item{limmashrink}{A logical. Should we apply hierarchical
shrinkage to the variances (\code{TRUE}) or not (\code{FALSE})?}

\item{fa_func}{A factor analysis function. The function must have
as inputs a numeric matrix \code{Y} and a rank (numeric scalar)
\code{r}. It must output a numeric matrix \code{alpha} and a
numeric vector \code{sig_diag}. \code{alpha} is the estimate of
the coefficients of the unobserved confounders, so it must be
an \code{r} by \code{ncol(Y)} matrix. \code{sig_diag} is the
estimate of the column-wise variances so it must be of length
\code{ncol(Y)}. The default is the function \code{pca_naive}
that just uses the first \code{r} singular vectors as the
estimate of \code{alpha}. The estimated variances are just the
column-wise mean square.}

\item{fa_args}{A list. Additional arguments you want to pass to
fa_func.}
}
\value{
Except for the list \code{ruv}, the values returned are the
    exact same as in \code{\link{ash.workhorse}}. See that function
    for more details. Elements in the \code{ruv} list are:

    \code{multiplier} A numeric. The estimated variance inflation parameter.

    \code{betahat_ols} A vector of numerics. The ordinary least
    squares estimates of the coefficients of the covariate of
    interest. This is when not including the estiamted confounding
    variables.

    \code{sebetahat_ols} A vector of positive numerics. The
    pre-inflation standard errors of \code{ruv$betahat} (NOT
    \code{ruv$betahat_ols}).

    \code{betahat} A vector of numerics. The ordinary least squares
    estimates of the coefficients of the covariate of interest WHEN
    YOU ALSO INCLUDE THE ESTIMATES OF THE UNOBSERVED CONFOUNDERS.

    \code{sebetahat} A vector of positive numerics. This is equal
    to sqrt(ruv$sebethat_ols * ruv$multiplier). This is the
    post-inflation adjusted standard errors for \code{ruv$betahat}.

    \code{tstats} A vector of numerics. The t-statistics for
    testing against the null hypothesis of the coefficient of the
    covariate of interest being zero.

    \code{pvalues} A vector of numerics. The p-values of said test
    above.

    \code{alphahat} A matrix of numerics. The estimates of the
    coefficients of the hidden confounders.

    \code{input} A list of arguments sent to
    \code{\link{ash.workhorse}}.

    \code{sigma2} A vector of positive numerics. The estimates of
    the variances.

    \code{fnorm_x} A numeric. This is the diagonal element of
    \code{t(X) \%*\% X} that corresponds to the covariate of
    interest. Returned mostly for debugging reasons and may be
    removed in the future.

    \code{Z1} A matrix of numerics of length 1. This is the
    estimated confounders (after a rotation). Not useful on it's
    own and is mostly returned for debugging purposes. It may be
    removed in the future.
}
\description{
This function will perform a variant of Removing Unwanted Variation
4-step (RUV4) (Gagnon-Bartsch et al, 2013) where the control genes
are used not only to estimate the hidden confounders, but to
estimate a variance inflation parameter. This variance inflation
step is akin to the "empirical null" approach of Efron
(2004). After this procedure, Adaptive SHrinkage (ASH) (Stephens,
2016) is performed on the coefficient estimates and the inflated
standard errors.
}
\details{
The model is \deqn{Y = XB + ZA + E,} where \eqn{Y} is a matrix of
responses (e.g. log-transformed gene expression levels), \eqn{X} is
a matrix of covariates, \eqn{B} is a matrix of coefficients,
\eqn{Z} is a matrix of unobserved confounders, \eqn{A} is a matrix
of unobserved coefficients of the unobserved confounders, and
\eqn{E} is the noise matrix where the elements are independent
Gaussian and each column shares a common variance. The rows of
\eqn{Y} are the observations (e.g. individuals) and the columns of
\eqn{Y} are the response variables (e.g. genes).

This model is fit using a two-step approach proposed in
Gagnon-Bartsch et al (2013) and described in Wang et al (2015),
modified to include estimating a variance inflation
parameter. Rather than use OLS in the second step of this two-step
procedure, we estimate the coefficients using Adaptive SHrinkage
(ASH) (Stephens, 2016). In the current implementation, only the
coefficients of one covariate can be estimated using ASH. The rest
are regressed out using OLS.
}
\author{
David Gerard
}
\references{
Gagnon-Bartsch, J., Laurent Jacob, and Terence
    P. Speed. "Removing unwanted variation from high dimensional
    data with negative controls."
    Berkeley: Department of Statistics. University of California
    (2013).

    Andreas Buja and Nermin Eyuboglu. "Remarks on parallel
    analysis." Multivariate behavioral research, 27(4):509â€“540,
    1992.

    Bradley Efron
    "Large-Scale Simultaneous Hypothesis Testing: The Choice of a Null
    Hypothesis",
    Journal of the American Statistical Association, 99:465,
    96-104, 2004.

    Stephens, Matthew. "False Discovery Rates: A New Deal." bioRxiv
    (2016): 038216.

    Wang, J., Zhao, Q., Hastie, T., & Owen, A. B
    "Confounder Adjustment in Multiple Hypotheses Testing."
    arXiv preprint arXiv:1508.04178 (2015).
}

